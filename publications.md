---
layout: page
permalink: /publications/index.html #/publications.html
title: Publications
---

<style>
  /* 自定义链接样式 */
  .custom-link—project {
    color: rgb(255,115,227);
  }
</style>

<style>
  /* 自定义链接样式 */
  .custom-link—code {
    color: rgb(103, 100, 248);
  }
</style>

<style>
  /* 自定义链接样式 */
  .custom-link—paper {
    color: rgb(39, 207, 236);
  }
</style>

# Publications

4&nbsp; **_CVPR_** / **_ICCV_** / **_ECCV_** &nbsp;&nbsp;&nbsp;5&nbsp; **_AAAI_** / **_IJCAI_** / **_ACM MM_** &nbsp;&nbsp;&nbsp; 1&nbsp; **_CVPRW_** / **_ICCVW_** / **_ECCVW_** &nbsp;&nbsp;&nbsp;2&nbsp; **_ACCV_** / **_BMVC_** &nbsp;&nbsp;&nbsp;2&nbsp; **_ICME_** / **_ICASSP_** &nbsp;&nbsp;&nbsp;

<!-- =================================================================================== -->
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>
    <tr>
      <td style="margin:5px;padding:5px;width:35%;max-width:90%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/CVPR24.png" alt="dise"> 
      </td>
      <td width="75%" valign="center" class="text-wrapper"> 
          <papertitle>
            <strong>
              Learning Diffusion Texture Priors for Image Restoration
            </strong>
          </papertitle>
          <br>
          Tian Ye, <strong><u>Sixiang Chen</u></strong>, Wenhao Chai, Zhaohu Xing, Jing Qin, Ge Lin, Lei Zhu<sup>✉️</sup>.
          <br>  
          <em>Computer Vision and Pattern Recognition <strong>(CVPR Highlight)</strong></em>, 2024
          <br>
          <a href="Ephemeral182.github.io" class="custom-link—paper">[Paper]</a>
          <a href="Ephemeral182.github.io" class="custom-link—code">[Code]</a>
      </td>
    </tr>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>
    <tr>
      <td style="margin:5px;padding:5px;width:35%;max-width:90%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/udrs2former.png" alt="dise"> 
      </td>
      <td width="75%" valign="center" class="text-wrapper"> 
          <papertitle>
            <strong>
              Sparse Sampling Transformer with Uncertainty-Driven Ranking for Unified Removal of Raindrops and Rain Streaks
            </strong>
          </papertitle>
          <br>
          <strong><u>Sixiang Chen*</u></strong>, Tian Ye*, Jinbin Bai, Jun Shi, Erkang Chen, Lei Zhu<sup>✉️</sup>.
          <br>  
          <em>International Conference on Computer Vision <strong>(ICCV)</strong></em>, 2023
          <br>
          <a href="https://arxiv.org/abs/2308.14153" class="custom-link—paper">[Paper]</a>
          <a href="https://github.com/Ephemeral182/UDR-S2Former_deraining" class="custom-link—code">[Code]</a>
          <a href="https://ephemeral182.github.io/UDR_S2Former_deraining/" class="custom-link—project">[Project]</a>
      </td>
    </tr>

 <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
          <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/AWRCP_framework.jpg" alt="dise"> 
        </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
        Adverse Weather Removal with Codebook Priors
        </strong>
        </papertitle>
        <br>
        Tian Ye*,<strong><u>Sixiang Chen*</u></strong>, Jinbin Bai, Jun Shi, Chenghao Xue, Jingjia Jiang, Junjie Yin, Erkang Chen, Yun Liu<sup>✉️</sup>.
        <br>  
        <em>International Conference on Computer Vision <strong>(ICCV)</strong></em>, 2023
        <br>
        <a href="Ephemeral182.github.io" class="custom-link—paper">[Paper]</a>
        <a href="Ephemeral182.github.io" class="custom-link—code">[Code]</a>
      </td>
      </tr>

  <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/Uncertainty_MM.png" alt="dise"> 
      </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
          Uncertainty-Driven Dynamic Degradation Perceiving and Background Modeling for Efficient Single Image Desnowing
        </strong>
        </papertitle>
        <br>
        <strong><u>Sixiang Chen*</u></strong>, Tian Ye*, Chenghao Xue*, Haoyu Chen, Yun Liu, Erkang Chen, Lei Zhu<sup>✉️</sup>.
        <br>  
        <em>ACM Multimedia <strong>(ACM MM)</strong></em>, 2023
        <br>
        <a href="Ephemeral182.github.io" class="custom-link—paper">[Paper]</a>
        <a href="Ephemeral182.github.io" class="custom-link—code">[Code]</a>
      </td>
      </tr>

  <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/cpl.png" alt="dise"> 
      </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
          CPLFormer: Cross-scale Prototype Learning Transformer for Image Snow Removal
        </strong>
        </papertitle>
        <br>
        <strong><u>Sixiang Chen*</u></strong>, Tian Ye*, Yun Liu, Jinbin Bai, Haoyu Chen, Yunlong Lin, Jun Shi, Erkang Chen<sup>✉️</sup>.
        <br>  
        <em>ACM Multimedia <strong>(ACM MM)</strong></em>, 2023
        <br>
        <a href="Ephemeral182.github.io" class="custom-link—paper">[Paper]</a>
       <a href="Ephemeral182.github.io" class="custom-link—code">[Code]</a>
      </td>
      </tr>

  <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/video.png" alt="dise"> 
      </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
          Sequential Affinity Learning for Video Restoration
        </strong>
        </papertitle>
        <br>
        Tian Ye*,<strong><u>Sixiang Chen*</u></strong>, Yun Liu<sup>✉️</sup>, Wenhao Chai, Jinbin Bai, Wenbin Zou, Yunchen Zhang, jiang mingchao, Erkang Chen, Chenghao Xue.
        <br>  
        <em>ACM Multimedia <strong>(ACM MM)</strong></em>, 2023
        <br>
        <a href="Ephemeral182.github.io" class="custom-link—paper">[Paper]</a>
        <a href="Ephemeral182.github.io" class="custom-link—code">[Code]</a>
      </td>
      </tr>

  <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/Nightformer.png" alt="dise"> 
      </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
          NightHazeFormer: Single Nighttime Haze Removal Using Prior Query Transformer
        </strong>
        </papertitle>
        <br>
        Yun Liu, Zhongsheng Yan, <strong><u>Sixiang Chen</u><sup>✉️</sup></strong>, Tian Ye<sup>✉️</sup>, Wenqi Ren, Erkang Chen.
        <br>  
        <em>ACM Multimedia <strong>(ACM MM)</strong></em>, 2023
        <br>
        <a href="http://export.arxiv.org/abs/2305.09533#:~:text=propose%20an%20end-to-end%20transformer-based%20framework%20for%20nighttime%20haze,we%20introduce%20two%20powerful%20priors%20into%20the%20transformer" class="custom-link—paper">[Paper]</a>
        <a href="Ephemeral182.github.io" class="custom-link—code">[Code]</a>
      </td>
      </tr>

  <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/BMVC.png" alt="dise"> 
      </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
          Five A+ Network: You Only Need 9K Parameters for Underwater Image Enhancement
        </strong>
        </papertitle>
        <br>
        Jingxia Jiang*, Tian Ye*, Jinbin Bai*, <strong><u>Sixiang Chen</u></strong>, Wenhao Chai, Jun Shi, Yun Liu, Erkang Chen<sup>✉️</sup>.
        <br>  
        <em>British Machine Vision Conference (BMVC)</em>, 2023
        <br>
        <a href="https://arxiv.org/abs/2305.08824#:~:text=In%20this%20work%2C%20we%20propose%20the%20Five%20A,The%20FA%20Net%20employs%20a%20two-stage%20enhancement%20structure." class="custom-link—paper">[Paper]</a>
        <a href="https://github.com/Owen718/FiveAPlus-Network" class="custom-link—code">[Code]</a>
      </td>
      </tr>

  <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/dehrformer_00.png" alt="dise"> 
      </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
          DEHRFormer: Real-time Transformer for Depth Estimation and Haze Removal from Varicolored Haze Scenes
        </strong>
        </papertitle>
        <br>
        <strong><u>Sixiang Chen*</u></strong>, Tian Ye*, Jun Shi, Yun Liu, JingXia Jiang, Erkang Chen, Peng Chen<sup>✉️</sup>.
        <br>  
        <em>International Conference on Acoustics, Speech, and Signal Processing <strong>(ICASSP)</strong></em>, 2023
        <br>
        <a href="https://ieeexplore.ieee.org/abstract/document/10096828" class="custom-link—paper">[Paper]</a>
        <a href="Ephemeral182.github.io" class="custom-link—code">[Code]</a>
      </td>
      </tr>

  <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/MSP-Former_00.png" alt="dise"> 
      </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
          MSP-Former: Multi-Scale Projection Transformer for Single Image Desnowing
        </strong>
        </papertitle>
        <br>
        <strong><u>Sixiang Chen*</u></strong>, Tian Ye*, Yun Liu, Taodong Liao, Jingxia Jiang, Erkang Chen, Peng Chen<sup>✉️</sup>.
        <br>  
        <em>International Conference on Acoustics, Speech, and Signal Processing <strong>(ICASSP)</strong></em>, 2023
        <br>
        <a href="https://ieeexplore.ieee.org/abstract/document/10095605" class="custom-link—paper">[Paper]</a>
        <a href="Ephemeral182.github.io" class="custom-link—code">[Code]</a>
      </td>
      </tr>

  <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/snowformer.png" alt="dise"> 
      </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
          SnowFormer: Context Interaction Transformer with Scale-awareness for Single Image Desnowing
        </strong>
        </papertitle>
        <br>
        <strong><u>Sixiang Chen*</u></strong>, Tian Ye*, Yun Liu, Erkang Chen<sup>✉️</sup>.
        <br>  
        <em>Arxiv (Under review)</em>, 2022
        <br>
        <a href="https://arxiv.org/abs/2208.09703#:~:text=SnowFormer%3A%20Context%20Interaction%20Transformer%20with%20Scale-awareness%20for%20Single,image%20desnowing%20is%20a%20challenging%20image%20restoration%20task." class="custom-link—paper">[Paper]</a>
        <a href="https://github.com/Ephemeral182/SnowFormer" class="custom-link—code">[Code]</a>
      </td>
      </tr>

  <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/ACCV.png" alt="dise"> 
      </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
          Towards Real-time High-Definition Image Snow Removal: Efficient Pyramid Network with Asymmetrical Encoder-decoder Architecture
        </strong>
        </papertitle>
        <br>
        Tian Ye*, <strong><u>Sixiang Chen*</u></strong>, Yun Liu, Yi Ye, Erkang Chen<sup>✉️</sup>.
        <br>  
        <em>Asian Conference on Computer Vision <strong>(ACCV)</strong></em>, 2022
        <br>
        <a href="Ephemeral182.github.io" class="custom-link—paper">[Paper]</a>
        <a href="Ephemeral182.github.io" class="custom-link—code">[Code]</a>
      </td>
      </tr>

  <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/dualformer.png" alt="dise"> 
      </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
          Dual-former: Hybrid Self-attention Transformer for
          Efficient Image Restoration
        </strong>
        </papertitle>
        <br>
        <strong><u>Sixiang Chen</u></strong>, Tian Ye, Yun Liu, Erkang Chen<sup>✉️</sup>.
        <br>  
        <em>Digital Signal Processing</em>, 2024
        <br>
        <a href="https://www.sciencedirect.com/science/article/pii/S1051200424001106" class="custom-link—paper">[Paper]</a>
        <a href="Ephemeral182.github.io" class="custom-link—code">[Code]</a>
      </td>
      </tr>

  <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/ECCV.png" alt="dise"> 
      </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
          Perceiving and Modeling Density for Image Dehazing
        </strong>
        </papertitle>
        <br>
        Tian Ye*, Mingchao Jiang*, Yunchen Zhang*, Liang Chen, Yun Liu, <strong><u>Sixiang Chen</u></strong>, Erkang Chen<sup>✉️</sup>.
        <br>  
        <em>European Conference on Computer Vision <strong>(ECCV Oral)</strong></em>, 2022
        <br>
        <a href="https://link.springer.com/chapter/10.1007/978-3-031-19800-7_8" class="custom-link—paper">[Paper]</a>
        <a href="https://github.com/Owen718/ECCV22-Perceiving-and-Modeling-Density-for-Image-Dehazing" class="custom-link—code">[Code]</a>
      </td>
      </tr>

  <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/CVPRW.png" alt="dise"> 
        </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
          Underwater Light Field Retention: Neural Rendering for Underwater Imaging
        </strong>
        </papertitle>
        <br>
        Tian Ye*, <strong><u>Sixiang Chen*</u></strong>, Yun Liu, Yi Ye, Erkang Chen<sup>✉️</sup>, Yuche Li.
        <br>  
        <em>Conference on Computer Vision and Pattern Recognition Workshop <strong>(CVPRW)</strong></em>, 2022
        <br>
        <a href="https://ieeexplore.ieee.org/document/9857150" class="custom-link—paper">[Paper]</a>
        <a href="https://github.com/Ephemeral182/UWNR" class="custom-link—code">[Code]</a>
      </td>
      </tr>
  </tbody>
</table>

<!-- =================================================================================== -->

---
